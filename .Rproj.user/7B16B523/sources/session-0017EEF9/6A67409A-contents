---
title: "Low input ChIP-seq analysis"
author: "Borja Gomez"
date: "2022-08-24"
output: html_document
---

## Introduction

Analysis of H3K27ac ChIP-seq data for smNPC, mDAN at days 30 and 50, and non-mDAN at day 50. Inputs are only available for neuronal samples, namely, smNPC sample has no input. For smNPC, there is only one replicate. For neuronal samples, there is a total of 2 replicates plus their corresponding inputs. 

The Low Cell ChIP-seq kit from Active Motif was used. Therefore, for the analysis of the sequencing data, their guidelines were followed. 

# Version of the different tools used

```{r}
samtools 1.9
Adapter Remval 2.2.2
bwa 0.7.17
fastqc 0.11.7
picard 2.18.13
paleomix 1.2.13.2
homer 4.10.4
bedtools 2.29.2
R 3.6
```

# Merging R1 and R2 files as first step

The fastq files came as 2 files per sample (R1 and R2). R2 MID needs to be merged into the header of R1 for the subsequent analysis. To do that, we need to uncompress the files and then run the scrips. Follow these commands:

```{r}
for R1 in *R1_001.fastq.gz
  do gunzip $R1 ${R1/_R1_/_R2_}
  fqR1=${R1/fastq.gz/fastq}
  echo ${fqR1/_R1_001.fastq/_combined.fastq.gz}
  paste <(paste - - - - <$fqR1) <(paste - - - - <${fqR1/_R1_/_R2_}) | \
    awk 'BEGIN{OFS=""}{print $1,"_",$8," ",$2,"\n",$3,"\n+\n",$5}' | \
    gzip - > ${fqR1/_R1_001.fastq/_combined.fastq.gz}
done

```

Then, files needs to be compressed again:

```{r}
parallel -j 12 "gzip {}" ::: *.fastq
```

To check if it worked, files can be visualized:

```{r}
#Compare with the previous files to observe the difference
less *.fastq.gz
```

# FastQC for the new combined files

Although trimming will be done later, it is good to take a look at the quality of the files after sequencing using FastQC (https://github.com/s-andrews/FastQC):

```{r}
ls *.gz | parallel -j 12 "fastqc --outdir=  {}" &
```

In order to obtain a report with for all samples, multiQC can be used (https://multiqc.info/):

```{r}
multiqc outdir
```

# Trimming and mapping using Paleomix

Here Paleomix (https://paleomix.readthedocs.io/en/stable/) will be used for the trimming of sequencing adaptors plus mapping to a reference genome:

```{r}
mkdir paleomix

#Create the makefile for trimming and mapping
paleomix bam_pipeline mkfile > paleo_trim.yaml

#In this directory place the reference genome
mkdir references
ln -s ~/GRCh38.p12.genome.fa references/
#Extension of the reference genome needs to be changed to .fasta 
```

Enter the **paleo_trim.yaml** and make the following modifications and place the sample names as indicated at the end:


```{r}
# -*- mode: Yaml; -*-
# Timestamp: 2020-02-11T11:20:53.077700
#
# Default options.
# Can also be specific for a set of samples, libraries, and lanes,
# by including the "Options" hierarchy at the same level as those
# samples, libraries, or lanes below. This does not include
# "Features", which may only be specific globally.
Options:
  # Sequencing platform, see SAM/BAM reference for valid values
  Platform: Illumina
  # Quality offset for Phred scores, either 33 (Sanger/Illumina 1.8+)
  # or 64 (Illumina 1.3+ / 1.5+). For Bowtie2 it is also possible to
  # specify 'Solexa', to handle reads on the Solexa scale. This is
  # used during adapter-trimming and sequence alignment
  QualityOffset: 33
  # Split a lane into multiple entries, one for each (pair of) file(s)
  # found using the search-string specified for a given lane. Each
  # lane is named by adding a number to the end of the given barcode.
  SplitLanesByFilenames: yes
  # Compression format for FASTQ reads; 'gz' for GZip, 'bz2' for BZip2
  CompressionFormat: gz

  # Settings for trimming of reads, see AdapterRemoval man-page
  AdapterRemoval:
     # Adapter sequences, set and uncomment to override defaults
#     --adapter1: AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC
#     --adapter2: AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTAGATCTCGGTGGTCGCCGTATCATT
     # Some BAM pipeline defaults differ from AR defaults;
     # To override, change these value(s):
     --mm: 3
     --minlength: 25
     # Extra features enabled by default; change 'yes' to 'no' to disable
     --collapse: yes
     --trimns: yes
     --trimqualities: yes

  # Settings for aligners supported by the pipeline
  Aligners:
    # Choice of aligner software to use, either "BWA" or "Bowtie2"
    Program: BWA

    # Settings for mappings performed using BWA
    BWA:
      # One of "backtrack", "bwasw", or "mem"; see the BWA documentation
      # for a description of each algorithm (defaults to 'backtrack')
      Algorithm: backtrack
      # Filter aligned reads with a mapping quality (Phred) below this value
      MinQuality: 0
      # Filter reads that did not map to the reference sequence
      FilterUnmappedReads: yes
      # May be disabled ("no") for aDNA alignments with the 'aln' algorithm.
      # Post-mortem damage localizes to the seed region, which BWA expects to
      # have few errors (sets "-l"). See http://pmid.us/22574660
      UseSeed: yes
      # Additional command-line options may be specified for the "aln"
      # call(s), as described below for Bowtie2 below.
# Settings for mappings performed using Bowtie2
    Bowtie2:
      # Filter aligned reads with a mapping quality (Phred) below this value
      MinQuality: 0
      # Filter reads that did not map to the reference sequence
      FilterUnmappedReads: yes
      # Examples of how to add additional command-line options
#      --trim5: 5
#      --trim3: 5
      # Note that the colon is required, even if no value is specified
      --very-sensitive:
      # Example of how to specify multiple values for an option
#      --rg:
#        - CN:SequencingCenterNameHere
#        - DS:DescriptionOfReadGroup

  # Mark / filter PCR duplicates. If set to 'filter', PCR duplicates are
  # removed from the output files; if set to 'mark', PCR duplicates are
  # flagged with bit 0x400, and not removed from the output files; if set to
  # 'no', the reads are assumed to not have been amplified. Collapsed reads
  # are filtered using the command 'paleomix rmdup_duplicates', while "normal"
  # reads are filtered using Picard MarkDuplicates.
  PCRDuplicates: mark

  # Command-line options for mapDamage; note that the long-form
  # options are expected; --length, not -l, etc. Uncomment the
  # "mapDamage" line adding command-line options below.
  mapDamage:
    # By default, the pipeline will downsample the input to 100k hits
    # when running mapDamage; remove to use all hits
    --downsample: 100000

  # Set to 'yes' exclude a type of trimmed reads from alignment / analysis;
  # possible read-types reflect the output of AdapterRemoval
  ExcludeReads:
    # Exclude single-end reads (yes / no)?
    Single: no
    # Exclude non-collapsed paired-end reads (yes / no)?
    Paired: no
    # Exclude paired-end reads for which the mate was discarded (yes / no)?
    Singleton: no
    # Exclude overlapping paired-ended reads collapsed into a single sequence
    # by AdapterRemoval (yes / no)?
    Collapsed: no
    # Like 'Collapsed', but only for collapsed reads truncated due to the
    # presence of ambiguous or low quality bases at read termini (yes / no).
    CollapsedTruncated: no

  # Optional steps to perform during processing.
  Features:
    # Generate BAM without realignment around indels (yes / no)
    RawBAM: yes
    # Generate indel-realigned BAM using the GATK Indel realigner (yes / no)
    RealignedBAM: no
 # To disable mapDamage, write 'no'; to generate basic mapDamage plots,
    # write 'plot'; to build post-mortem damage models, write 'model',
    # and to produce rescaled BAMs, write 'rescale'. The 'model' option
    # includes the 'plot' output, and the 'rescale' option includes both
    # 'plot' and 'model' results. All analyses are carried out per library.
    mapDamage: no
    # Generate coverage information for the raw BAM (wo/ indel realignment).
    # If one or more 'RegionsOfInterest' have been specified for a prefix,
    # additional coverage files are generated for each alignment (yes / no)
    Coverage: yes
    # Generate histogram of number of sites with a given read-depth, from 0
    # to 200. If one or more 'RegionsOfInterest' have been specified for a
    # prefix, additional histograms are generated for each alignment (yes / no)
    Depths: no
    # Generate summary table for each target (yes / no)
    Summary: yes
    # Generate histogram of PCR duplicates, for use with PreSeq (yes / no)
    DuplicateHist: no


# Map of prefixes by name, each having a Path key, which specifies the
# location of the BWA/Bowtie2 index, and optional label, and an option
# set of regions for which additional statistics are produced.
Prefixes:
  # Replace 'NAME_OF_PREFIX' with name of the prefix; this name
  # is used in summary statistics and as part of output filenames.
  GRCh38.p12:
    # Replace 'PATH_TO_PREFIX' with the path to .fasta file containing the
    # references against which reads are to be mapped. Using the same name
    # as filename is strongly recommended (e.g. /path/to/Human_g1k_v37.fasta
    # should be named 'Human_g1k_v37').
    Path: references/GRCh38.p12.genome.fasta

    # (Optional) Uncomment and replace 'PATH_TO_BEDFILE' with the path to a
    # .bed file listing extra regions for which coverage / depth statistics
    # should be calculated; if no names are specified for the BED records,
    # results are named after the chromosome / contig. Change 'NAME' to the
    # name to be used in summary statistics and output filenames.
#    RegionsOfInterest:
#      NAME: PATH_TO_BEDFILE


# Mapping targets are specified using the following structure. Uncomment and
# replace 'NAME_OF_TARGET' with the desired prefix for filenames.
#NAME_OF_TARGET:
   #  Uncomment and replace 'NAME_OF_SAMPLE' with the name of this sample.
#  NAME_OF_SAMPLE:
     #  Uncomment and replace 'NAME_OF_LIBRARY' with the name of this sample.
#    NAME_OF_LIBRARY:
       # Uncomment and replace 'NAME_OF_LANE' with the name of this lane,
       # and replace 'PATH_WITH_WILDCARDS' with the path to the FASTQ files
       # to be trimmed and mapped for this lane (may include wildcards).
#      NAME_OF_LANE: PATH_WITH_WILDCARDS
D30pos_H3K27ac_Ind13:
  D30pos_H3K27ac_Ind13:
    D30pos_H3K27ac_Ind13:
      "D30pos_H3K27ac_Ind13": fastq_combined/HFFTHmCherry_D30pos_H3K27ac_Ind13_Lasse_S7_combined.fastq.gz
D30pos_input_Ind14:
  D30pos_input_Ind14:
    D30pos_input_Ind14:
      "D30pos_input_Ind14": fastq_combined/HFFTHmCherry_D30pos_input_Ind14_Lasse_S8_combined.fastq.gz
...
```

Once the modified, save it and close. For running Paleomix, the best is to place the folder containing the fastq files inside the paleomix folder. In the example below the folder is called **fastq_combined**. Use this information as a reference

To run paleomix:

```{r}
paleomix bam_pipeline run --bwa-max-threads=4 --adapterremoval-max-threads=4 --max-threads=24 paleo_trim.yaml
```


# FastQC on truncated.gz files

Extract the truncated files created by Paleomix:

```{r}
find -name "*truncated.gz" | awk '{split($1, path, "/"); system("mv "$1 " "path[2] "_" path[7])}'
```

Then, FastQC can be run in the new files:

```{r}
ls *truncated.gz | parallel -j 12 "fastqc --outdir=  {}" &
```

Again, to obtain a report with all the samples, use multiqc

```{r}
multiqc outdir
```

# Picard for the validation of the bam files

As paleomix also produced the .bam files, they need to be validated to check there are not errors (https://github.com/broadinstitute/picard):

```{r}
#Java needs to be loaded as Picard runs in Java
parallel -j 12 "java -jar ~/jar_root/picard.jar ValidateSamFile I={} O={.}.validated IGNORE=MISSING_TAG_NM IGNORE=MISSING_READ_GROUP IGNORE=READ_GROUP_NOT_FOUND IGNORE_WARNINGS=TRUE" ::: *.bam
```

Check the new **.validated** files. They should contain no errors. 

# Q30 filtering for quality reads

Samtools was used for Q30 filtering of quality reads and reduce the possibility of having false positives in the data (https://github.com/samtools/samtools):

```{r}
parallel -j 12 "samtools view -b -q 30 {} > ~/"{.}".q30.bam" ::: *.bam
```

# Sorting bam files by mapping positions

As this pipeline contains a de-duping step (please go to Active Motif documentantion to know about this step in the processin of the data), bam files need to be prepared before that step. So, the following was run:

```{r}
parallel -j 12 "samtools sort {} -o ~/"{.}".sort.bam" ::: *.q30.bam
```

# Molecular identifier (MID) De-duping

For the de-duping step, script from Active Motif would need to be requested. **It is not included in this pipeline because we did not receive a confirmation from Active Motif about making it public**

MIDs were incorporated during library preparation and serve to remove PCR duplicates. 

Once this step is done, the files to continue working with would be **.rmdup.bam**

# HOMER for processing bam files and detecting super-enhancers

HOMER was used for processing the bam files and detect super-enhancer regions (http://homer.ucsd.edu/homer/index.html). First a TagDirectory per sample needs to be created:

```{r}
#First the tagdir folder needs to be created
mkdir tagdir

for rmdup in *sort.rmdup.bam
  do makeTagDirectory ~/tagdir/$rmdup ~/${rmdup}
done
```

Call enhancers and super-enhancers in the data:

```{r}
#With this command, we are considering a super-enhancer a region with a minimum of 10kb. Take into account that here we are using the input bam files to 
findPeaks <tagDire> -style \
  super -typical \
  <name>.TE -o \
  <name>.SE -L 0 -minDist 10000 -i <tagDir_INPUT>
```

Two files would be produced with this command, **.TE** would be normal enhancers while **.SE** would be the super-enhancers. 

Now, it order to produce **.bed** files type:

```{r}
pos2bed.pl *.SE > *.SE.bed
```

Then, bedtools was used for merging the files (https://bedtools.readthedocs.io/en/latest/):

```{r}
#First, .bed files had to be sorted and then they can be merged. 
cat *.SE.bed *.SE.bed | sort -k1,1 -k2,2n | bedtools merge -s -c 4 -o distinct > *merged.SE.bed
```

Basically, super-enhancers from duplicates were merged. The same can be done for normal enhancers (.TE)

# Association of TFs to super-enhancers

Before doing this association, additional files have to be prepared:

- Annotation file with only information about genes (gencode.v31.annotation.gff3 was used). As an example, **annotation_genes** would represent this file to understand the commands.
- Two independent files file containing the expressed genes from mDAN at days 30 and 50. Gene counts for this time point can be extracted from the RNA-seq data. In this study, a gene containing more than 10 reads was considered as expressed. **Genes_day30** and **Genes_day50** would be used in the following commands as a representation of that. 

Create a file with the coordinates for the expressed genes at days 30 and 50. This coordinates would be basically the gene body of the expressed genes:

```{r}
#Use tidyverse for processing the data 
#library(tidyverse)
inner_join(annotation_genes,
          Genes_day30,
          by = "gene_id") -> coord_D30_genes

coord_D30_genes %>% dplyr::select(seqnames, start, end, gene_id) ->  coord_D30_genes

inner_join(annotation_genes,
          Genes_day50,
          by = "gene_id") -> coord_D50_genes

coord_D50_genes %>% dplyr::select(seqnames, start, end, gene_id) -> coord_D50_genes
```

Now, a bed file needs to be created to do the association:

```{r}
write.table(coord_D30_genes, "~/Genes_D30_coor.bed", sep = "\t", col.names = FALSE, row.names = FALSE, quote = FALSE)

write.table(coord_D50_genes, "~/Genes_D50_coor.bed", sep = "\t", col.names = FALSE, row.names = FALSE, quote = FALSE)
```

Now, bedtools were used again for the intersection of super-enhancers with expressed genes

```{r}
bedtools intersect -a Genes_D30_coor.bed -b mDAN_Day30_merged.SE.bed -wb > D30_SE_assigned_genes.bed

bedtools intersect -a Genes_D50_coor.bed -b mDAN_Day50_merged.SE.bed -wb > D50_SE_assigned_genes.bed
```

Now, we used a list of curated human TFs from the following publication:

**Heinäniemi, M., Nykter, M., Kramer, R., Wienecke-Baldacchino, A., Sinkkonen, L., Zhou, J. X., … Shmulevich, I. (2013). Gene-pair expression signatures reveal lineage control. Nature Methods, 10(6), 577–583. https://doi.org/10.1038/nmeth.2445**

The list of TFs was overlapped with the genes assigned to super-enhancers:

```{r}
#If necessary, transform gene ids to gene names using annotation file 
inner_join(D30_SE_assigned_genes,
           TF_list,
           by = "gene_name") %>% distinct(gene_name) -> D30_TF_SE

inner_join(D50_SE_assigned_genes,
           TF_list,
           by = "gene_name") %>% distinct(gene_name) -> D50_TF_SE

#For merging both list and getting the total number of TFs associated to SE

rbind(D30_TF_SE, D50_TF_SE) %>% distinct() -> All_TF_SE
```














